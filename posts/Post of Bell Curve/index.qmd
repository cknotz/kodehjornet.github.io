---
title: "The normal distribution"
author: "Knut Solvig"
date: "2023-09-26"
categories: [how-to, code, case, selection, quantitative]
image: "titleimage.png"
---

In this blog post I wish to use some time to talk about the normal distribution or the *bell curve.*

The normal distribution is the ideal distribution of data as it is very easy to intepret, but even though it is called a *normal* distribution - it rarely occurs in scientific analyses.

Below you can see what a bell curve looks like in a simplified format in @fig-bellcurve:

```{r}
#| label: fig-bellcurve
#| fig-cap: "A traditional bell curve."
#| warning: false
X <- seq(from=-3, to=3, length.out=1000)

f.x <- dnorm(X, mean = 0, sd = 1)

plot(X, f.x, type = 'l', col = "red", lwd=3)
```

The great thing about a bell curve is that you can use the **68-95-99** rule on it (like mentioned in Kellstedt & Whitten page. 150). This rule is basically the amount of data that are within the standard deviations of the mean in the graph. See the example below:

![](images/bellcurve_standarddeviation-01.png){width="392"}

![](images/95percent.png){width="387"}

![](images/99percent.png){width="389"}

A way to understand how the bell curve works is to imagine that you roll a dice 1000 times. You are more likely to get a 3 or a 4 than you are to get 6 or 1, in that way everytime you plot into your dataset a dice throw you are creating a graph which should be relatively evenly distributed - like a bell curve.

Thank you for reading, I hope you are now a *little bit* smarter around the topic of the normal distribution - also called a *bell curve*.
